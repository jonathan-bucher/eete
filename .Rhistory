data_reg = data |>
mutate(sh_experienced = ifelse(sh_experienced == "Yes, It Happened To Me", 1, 0),
sh_report = case_when(sh_experienced == "Yes, It Happened To Me" &
sh_report == "Yes" ~ 1,
sh_experienced == "Yes, It Happened To Me" &
sh_experienced == "No" ~ 0,
TRUE ~ NA),
pt_user = ifelse(pt_user == "Public Transport User", 1, 0),
female = ifelse(gender == "Female", 1, 0)) |>
filter(pt_user == 1)
mod1 = glm(sh_experienced ~ female, data = data_reg, family = binomial(link = "logit"))
summary(mod1)
setwd("/Users/kairytales/Desktop/CAL POLY/WINTER 2024/World Bank/NCRTC")
help("glm")
library(tidyverse)
data = read_csv("/Users/kairytales/Desktop/CAL POLY/WINTER 2024/paeco526_take_home_final.csv")
#| message: false
#| warning: false
data = read_csv("/Users/kairytales/Desktop/CAL POLY/WINTER 2024/paeco526_take_home_final.csv")
#| message: false
#| warning: false
data = read_csv("/Users/kairytales/Desktop/CAL POLY/WINTER 2024/paeco526_take_home_final.csv")
View(data)
mod1 = lm(dbirwt ~ tobacco, data = data)
summary(mod1)
2/21
probs <- fitted(nl, type="probabilities")
#Question 1
library(readxl)
#Question 1
library(readxl)
camp <- read_excel(path = "campingdemand.xlsx")
getwd()
setwd("/Users/kairytales/Desktop/CAL POLY/WINTER 2024")
#Part A
library(mlogit)
#Question 1
library(readxl)
camp <- read_excel(path = "campingdemand.xlsx")
#Question 1
library(readxl)
camp <- read_excel(path = "campingdemand.xlsx")
#Part A
library(mlogit)
camp_dfidx <-dfidx(data=camp, shape="long", choice="visit",
idx=c('camper_id', 'park_id'))
ml <- mlogit(formula = visit ~ cost + time + mountain | 0, data = camp_dfidx)
summary(ml)
#Part B
nl <- mlogit(formula = visit ~ cost + time + mountain | 0, data = camp_dfidx,
nests = list(mountain = 1:2, beach=3:5))
summary(nl)
#Part C
lrtest(ml, nl)
#Part D
coef(nl)[2:3]/coef(nl)[1]*c(60, -1)
#Part E
probs <- fitted(nl, type="probabilities")
library(tidyverse)
camp %>% tidyverse::filter(park_id == 1) %>%
mutate(prob = probs[, 1],
prob_nest = rowSums(probs[, 1:2]),
prob_cond = prob / prob_nest,
own_elas = coef(nl)[1]*cost*((1/coef(nl)[4])-((1-coef(nl)[4]) / coef(nl)[4]*prob_cond)-prob),
cross_elas_mountain = -coef(nl)[1]*cost*prob*(1+((1-coef(nl)[4])/(coef(nl)[4]*prob_nest))),
cross_elas_beach = -coef(nl)[1]*cost*prob) %>%
summarize(own_elas = mean(own_elas),
cross_elas_mountain = mean(cross_elas_mountain),
cross_elas_beach = mean(cross_elas_beach))
#Question 1
library(readxl)
camp <- read_excel(path = "campingdemand.xlsx")
#Part A
library(mlogit)
camp_dfidx <-dfidx(data=camp, shape="long", choice="visit",
idx=c('camper_id', 'park_id'))
ml <- mlogit(formula = visit ~ cost + time + mountain | 0, data = camp_dfidx)
summary(ml)
#Part B
nl <- mlogit(formula = visit ~ cost + time + mountain | 0, data = camp_dfidx,
nests = list(mountain = 1:2, beach=3:5))
summary(nl)
#Part C
lrtest(ml, nl)
#Part D
coef(nl)[2:3]/coef(nl)[1]*c(60, -1)
#Part E
probs <- fitted(nl, type="probabilities")
library(tidyverse)
camp %>% dplyr::filter(park_id == 1) %>%
mutate(prob = probs[, 1],
prob_nest = rowSums(probs[, 1:2]),
prob_cond = prob / prob_nest,
own_elas = coef(nl)[1]*cost*((1/coef(nl)[4])-((1-coef(nl)[4]) / coef(nl)[4]*prob_cond)-prob),
cross_elas_mountain = -coef(nl)[1]*cost*prob*(1+((1-coef(nl)[4])/(coef(nl)[4]*prob_nest))),
cross_elas_beach = -coef(nl)[1]*cost*prob) %>%
summarize(own_elas = mean(own_elas),
cross_elas_mountain = mean(cross_elas_mountain),
cross_elas_beach = mean(cross_elas_beach))
#Part F
mixl <- mlogit(formula = visit ~ cost + time + mountain |0, data = camp_dfidx,
rpar = c(time = "n", mountain = "n"),
R = 100, seed=500)
summary(mixl)
#Part G
c(coef(mixl)[2]/coef(mixl)[1]*60, abs(coef(mixl)[4])/-coef(mixl)[1]*60) %>%
setNames(c("time", "sd.time"))
c(coef(mixl)[3]/-coef(mixl)[1], abs(coef(mixl)[5])/-coef(mixl)[1]) %>%
setNames(c("mountain", "sd.mountain"))
#Part H
1 - pnorm(q=0, mean = coef(mixl)[3]/-coef(mixl)[1],
sd=abs(coef(mixl)[5])/-coef(mixl)[1])
#Part I
camp_cf <- camp %>% mutate(cost = if_else(park_id == 1, cost+20, cost))
camp_cf_dfidx <-dfidx(data=camp_cf, shape="long", choice="visit", idx=c("camper_id", "park_id"))
choice_obs <-predict(mixl, newdata=camp_dfidx)
choice_cf <-predict(mixl, newdata=camp_cf_dfidx)
colSums(choice_cf-choice_obs)
#Park J
logsum_obs <-logsum(mixl, data=camp_dfidx)
logsum_cf <- logsum(mixl, data=camp_cf_dfidx)
sum((logsum_cf - logsum_obs))/ -coef(mixl)[1]
#Question 1
library(readxl)
camp <- read_excel(path = "campingdemand.xlsx")
#Part A
library(mlogit)
camp_dfidx <-dfidx(data=camp, shape="long", choice="visit",
idx=c('camper_id', 'park_id'))
ml <- mlogit(formula = visit ~ cost + time + mountain | 0, data = camp_dfidx)
summary(ml)
#Part B
nl <- mlogit(formula = visit ~ cost + time + mountain | 0, data = camp_dfidx,
nests = list(mountain = 1:2, beach=3:5))
summary(nl)
#Part C
lrtest(ml, nl)
#Part D
coef(nl)[2:3]/coef(nl)[1]*c(60, -1)
coef(nl)[1]
coef(nl)[2:3]
coef(nl)[2:3]/coef(nl)[1]
help(ecrcd)
library(eete)
help(ecrcd)
help(eete)
setwd("/Users/kairytales/Desktop/CAL POLY/FALL 2023/Research/eete")
help(ecrcd, eete)
??ecrcd
help(ecacd)
help(eete)
help(ebounds)
help("filter")
help("ecrcd")
library(eete)
devtools::document()
?ebounds
help(ecrcd)
253-175
52/4*1000
#| message: false
library(eete)
library(tidyverse)
library(broom)
library(haven)
library(sjmisc)
library(AER)
library(kableExtra)
library(boot)
library(purrr)
106.57 + 24.92
devtools::build_vignettes()
devtools::install()
devtools::check()
#| message: false
library(eete)
library(tidyverse)
library(broom)
library(haven)
library(sjmisc)
library(AER)
library(kableExtra)
library(boot)
library(purrr)
devtools::document()
devtools::document()
devtools::document()
devtools::build_vignettes()
vignette()
vignette(eete)
vignette(tibble)
pivot.vignette()
help("vignette")
vignette(package = "pivot")
vignette(package = "grid")
vignette("frame", package = "grid")
help(frame)
data = read_csv("/Users/kairytales/Downloads/data_in_class_three.csv")
View(data)
X = data$Cal_Poly_GPA
exam_mean = alpha + beta*X
mod1 = lm(ETS_scaled_score ~ Cal_Poly_GPA, data = data)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = 3.4))
sig = var(data$Cal_Poly_GPA)
n = nrow(data)
new_gpa + sqrt(sig/n)
new_gpa = 3.4
mod1 = lm(ETS_scaled_score ~ Cal_Poly_GPA, data = data)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = new_gpa))
sig = var(data$Cal_Poly_GPA)
n = nrow(data)
new_gpa + sqrt(sig/n)
sig = var(data$Cal_Poly_GPA)
sig
sig = var(data$Cal_Poly_GPA, na.rm = TRUE)
n = nrow(data)
new_gpa + sqrt(sig/n)
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1/n + (x_0 - x_bar)^2/sxx)
x_0 = 3.4
mod1 = lm(ETS_scaled_score ~ Cal_Poly_GPA, data = data)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0))
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1/n + (x_0 - x_bar)^2/sxx)
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
var_prediction
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
sqrt(var_prediction)
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0)) + sqrt(var_prediction)
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0)) + sqrt(var_prediction)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0)) - sqrt(var_prediction)
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0)) + 1.96*sqrt(var_prediction)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0)) - 1.96*sqrt(var_prediction)
n = nrow(data)
x_bar = mean(data$Cal_Poly_GPA, na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0)) + 1.96*sqrt(var_prediction/n)
predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0)) - 1.96*sqrt(var_prediction/n)
data_34 = data[data$Cal_Poly_GPA == x_0]
mean(data$ETS_scaled_score[data$Cal_Poly_GPA > 3.39 & data$Cal_Poly_GPA < 3.50])
mean(data$ETS_scaled_score[data$Cal_Poly_GPA > 3.39 & data$Cal_Poly_GPA < 3.50], na.rm = TRUE)
x_bar_34 = mean(data$ETS_scaled_score[data$Cal_Poly_GPA > 3.39 & data$Cal_Poly_GPA < 3.50], na.rm = TRUE)
sxx = var(data$Cal_Poly_GPA, na.rm = TRUE)
var_prediction = sig_squared * (1/n + (x_0 - x_bar_34)^2/sxx)
upper_bound = x_bar_34 + 1.96*sqrt(var_prediction/n)
lower_bound = x_bar_34 - 1.96*sqrt(var_prediction/n)
summary(mod1)
x_0 = 3.4
mod1 = lm(ETS_scaled_score ~ ECON_GPA, data = data)
score_hat = predict(mod1, newdata = data.frame(Cal_Poly_GPA = x_0))
data = read_csv("/Users/kairytales/Downloads/data_in_class_three.csv")
x_0 = 3.4
mod1 = lm(ETS_scaled_score ~ ECON_GPA, data = data)
score_hat = predict(mod1, newdata = data.frame(ECON_GPA = x_0))
x_0 = 3.4
mod1 = lm(ETS_scaled_score ~ ECON_GPA, data = data)
score_hat = predict(mod1, newdata = data.frame(ECON_GPA = x_0))
score_hat
n = nrow(data)
x_bar = mean(data$CECON_GPA, na.rm = TRUE)
sxx = var(data$ECON_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
upper_bound = score_hat + 1.96*sqrt(var_prediction/n)
lower_bound = score_hat - 1.96*sqrt(var_prediction/n)
n = nrow(data)
x_bar = mean(data$ECON_GPA, na.rm = TRUE)
sxx = var(data$ECON_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
upper_bound = score_hat + 1.96*sqrt(var_prediction/n)
lower_bound = score_hat - 1.96*sqrt(var_prediction/n)
n = nrow(data)
x_bar = mean(data$ECON_GPA, na.rm = TRUE)
sxx = var(data$ECON_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
upper_bound = score_hat + 1.96*sqrt(var_prediction/n)
lower_bound = score_hat - 1.96*sqrt(var_prediction/n)
upper_bound
lower_bound
n = nrow(data)
x_bar = mean(data$ECON_GPA, na.rm = TRUE)
sxx = var(data$ECON_GPA, na.rm = TRUE)
sig_squared = var(data$ETS_scaled_score)
var_prediction = sig_squared * (1 + 1/n + (x_0 - x_bar)^2/sxx)
upper_bound = score_hat + 1.96*sqrt(var_prediction)
lower_bound = score_hat - 1.96*sqrt(var_prediction)
upper_bound
lower_bound
predict(mod1, newdata = data.frame(ECON_GPA = x_0), interval = "prediction", level = 0.95)
predict(mod1, newdata = data.frame(ECON_GPA = x_0), interval = "confidence", level = 0.95)
predict(mod1, newdata = data.frame(ECON_GPA = x_0), interval = "prediction", level = 0.95)
view(predict())
view(predict)
help("predict")
help(pnorm)
help("predict")
predict
view(predict)
dnorm(x_0, mean = 162.7533, sd = 10)
pnorm(x_0, mean = 162.7533, sd = 10)
qnorm(x_0, mean = 162.7533, sd = 10)
pnorm(x_0, mean = 162.7533, sd = 10)
pnorm(x_0, mean = 162.7533, sd = 3)
pnorm(x_0, mean = 162.7533, sd = 1)
x1 = data$ETS_scaled_score
x2 = data$ECON_GPA
mean_x1 = mean(x1, na.rm = TRUE)
var_x1 = var(x1, na.rm = TRUE)
mean_x2 = mean(x2, na.rm = TRUE)
var_x2 = var(x1, na.rm = TRUE)
cov_x12 = cov(x1, x2)
x2_given = 3.4
Ex1_x2 = mean_x1 + cov_x12/var_x2 * (x2_given - mean_x2)
Ex1_x2
varx1_x2 = var_x1 - (cov_x12)^2/var_x2
varx1_x2
x1_given = 157
dnorm(x1_given, Ex1_x2, sqrt(varx1_x2))
x1 = data$ETS_scaled_score
x2 = data$ECON_GPA
mean_x1 = mean(x1, na.rm = TRUE)
var_x1 = var(x1, na.rm = TRUE)
mean_x2 = mean(x2, na.rm = TRUE)
var_x2 = var(x1, na.rm = TRUE)
cov_x12 = cov(x1, x2)
x2_given = 3.4
Ex1_x2 = mean_x1 + cov_x12/var_x2 * (x2_given - mean_x2)
Ex1_x2
varx1_x2 = var_x1 - (cov_x12)^2/var_x2
varx1_x2
x1_given = 157
1-pnorm(x1_given, mean = Ex1_x2, sd = sqrt(varx1_x2))
x1_given = 169
1-pnorm(x1_given, mean = Ex1_x2, sd = sqrt(varx1_x2))
mean_x1 + cov_x12/var_x2
(x2_given - mean_x2)
x1 = data$ETS_scaled_score
x2 = data$ECON_GPA
mean_x1 = mean(x1, na.rm = TRUE)
var_x1 = var(x1, na.rm = TRUE)
mean_x2 = mean(x2, na.rm = TRUE)
var_x2 = var(x1, na.rm = TRUE)
cov_x12 = cov(x1, x2)
x2_given = 3.4
Ex1_x2 = mean_x1 + cov_x12/var_x2 * (x2_given - mean_x2)
Ex1_x2
varx1_x2 = var_x1 - (cov_x12)^2/var_x2
varx1_x2
x1_given = 157
1-pnorm(x1_given, mean = 162.7533, sd = sqrt(varx1_x2))
var(data[data$ECON_464_Grade == 3.4], na.rm = TRUE)
mean_x1 <- mean(data$ETS_scaled_score, na.rm = TRUE)
var_x1 <- var(data$ETS_scaled_score, na.rm = TRUE)
mean_x2 <- mean(data$ECON_GPA, na.rm = TRUE)
var_x2 <- var(data$ECON_GPA, na.rm = TRUE)
cov_x12 <- cov(data$ETS_scaled_score, data$ECON_GPA)
var_x1 - (cov_x12^2 / var_x2)
x1 = data$ETS_scaled_score
x2 = data$ECON_GPA
mean_x1 = mean(x1, na.rm = TRUE)
var_x1 = var(x1, na.rm = TRUE)
mean_x2 = mean(x2, na.rm = TRUE)
var_x2 = var(x2, na.rm = TRUE)
cov_x12 = cov(x1, x2)
x2_given = 3.4
Ex1_x2 = mean_x1 + cov_x12/var_x2 * (x2_given - mean_x2)
Ex1_x2
varx1_x2 = var_x1 - (cov_x12)^2/var_x2
varx1_x2
x1_given = 157
1-pnorm(x1_given, mean = 162.7533, sd = sqrt(varx1_x2))
x1_given = 169
1-pnorm(x1_given, mean = Ex1_x2, sd = sqrt(varx1_x2))
x1 = data$ETS_scaled_score
x2 = data$ECON_GPA
mean_x1 = mean(x1, na.rm = TRUE)
var_x1 = var(x1, na.rm = TRUE)
mean_x2 = mean(x2, na.rm = TRUE)
var_x2 = var(x2, na.rm = TRUE)
cov_x12 = cov(x1, x2)
x2_given = 3.4
Ex1_x2 = mean_x1 + cov_x12/var_x2 * (x2_given - mean_x2)
Ex1_x2
varx1_x2 = var_x1 - (cov_x12)^2/var_x2
varx1_x2
x1_given = 157
1-pnorm(x1_given, mean = Ex1_x2, sd = sqrt(varx1_x2))
library(tidyverse)
library(eete)
SIPP1991 = read_dta('data/Angrist 1991 SIPP.dta')
setwd("/Users/kairytales/Desktop/CAL POLY/FALL 2023/Research/eete")
SIPP1991 = read_dta('data/Angrist 1991 SIPP.dta')
getwd()
SIPP1991 = read_dta('../data/Angrist 1991 SIPP.dta')
SIPP1991_edit <- SIPP1991 |>
mutate(rsncode = ifelse(rsncode == 999, NA, rsncode),
wage = kwage,
lwage = log(kwage))
devtools::document()
devtools::document()
devtools::build_vignettes()
devtools::document()
help(read_dta)
devtools::document()
devtools::build_vignettes()
devtools::document()
devtools::build_vignettes()
devtools::document()
devtools::document()
devtools::build_vignettes()
library(tidyverse)
library(haven)
library(eete)
SIPP1991 = read_dta('../data/Angrist 1991 SIPP.dta')
SIPP1991_edit <- SIPP1991 |>
mutate(rsncode = ifelse(rsncode == 999, NA, rsncode),
wage = kwage,
lwage = log(kwage))
eete(crpie, gam = 0, y = "lwage", d = "nvstat", z = "rsncode", data = SIPP1991_edit)
eete(cdpie, r = 1, y = "lwage", d = "nvstat", z = "rsncode", data = SIPP1991_edit)
ebounds(crpie, gam = 2, y = "lwage", d = "nvstat", z = "rsncode", data = SIPP1991_edit, se = TRUE)
library(tidyverse)
library(haven)
library(eete)
eete(crpie, gam = 0, y = "lwage", d = "nvstat", z = "rsncode", data = SIPP1991_edit)
eete(cdpie, r = 1, y = "lwage", d = "nvstat", z = "rsncode", data = SIPP1991_edit)
install.packages("eete")
install.packages("eete")
install.packages('/Users/kairytales/Desktop/CAL POLY/FALL 2023/Research/eete', repos=NULL, type='source')
library(eete)
devtools::document()
devtools::build_vignettes()
install.packages('/Users/kairytales/Desktop/CAL POLY/FALL 2023/Research/eete', repos=NULL, type='source')
library(eete)
devtools::document()
devtools::build_vignettes()
devtools::build_vignettes()
devtools::document()
devtools::build_vignettes()
#| code-line-numbers: "|1|2-3|5-10|12-17"
ecacd = function(x, r = NULL, L = NULL){
if (is.null(r) & is.null(L)){
val = "Please provide a value for r or L."
} else if (!is.null(r)){
if (r != 0){
val = -exp(-x/r)
}else{
val = "Please use r > 0"
}
} else if (!is.null(L)){
if (L != 0){
val = -2^(-x/L)
}else{
val = "Please use L > 0"
}
}
return(val)
}
#| code-line-numbers: "|1|2-3|5-10|12-17"
ecacd = function(x, r = NULL, L = NULL){
if (is.null(r) & is.null(L)){
val = "Please provide a value for r or L."
} else if (!is.null(r)){
if (r != 0){
val = -exp(-x/r)
}else{
val = "Please use r > 0"
}
} else if (!is.null(L)){
if (L != 0){
val = -2^(-x/L)
}else{
val = "Please use L > 0"
}
}
return(val)
}
help(rank)
help("quantile")
